{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import datetime\n",
    "import os\n",
    "import base64\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import sqlite3\n",
    "from utils.pipeline import get_files\n",
    "from utils.tools import seconds_to_time\n",
    "# Set the maximum number of rows and columns to display\n",
    "pd.set_option('display.max_rows', 1000)  # Adjust the number as needed\n",
    "pd.set_option('display.max_columns', 1000)  # Adjust the number as needed\n",
    "\n",
    "files = get_files('/home/diego/Documents/yolov7-tracker/runs/detect/2024_04_17_conce_bytetrack')\n",
    "db = files['db']\n",
    "FRAME_NUMBER = 15\n",
    "conn = sqlite3.connect(db)\n",
    "cursor = conn.cursor()    \n",
    "bbox = pd.read_sql('SELECT * FROM bbox_raw', conn)\n",
    "bbox['direction'] = bbox.apply(lambda row: ('undefined' if row['img_name'].split('_')[3] == 'None' else  row['img_name'].split('_')[3]) if row['img_name'] is not None else None, axis=1)\n",
    "bbox['time_sec'] = bbox.apply(lambda row: int(row['frame_number']) // FRAME_NUMBER, axis=1)\n",
    "bbox['time_video'] = pd.to_datetime(bbox['time_sec'], unit='s').dt.time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_direction_info(df):\n",
    "    # Using .copy() to ensure the original dataframe is not affected\n",
    "    temp_df = df.copy()\n",
    "    first_directions = temp_df.groupby('id')['direction'].first().reset_index()\n",
    "    direction_counts = first_directions['direction'].value_counts().to_dict()\n",
    "    result = {k.lower(): v for k, v in direction_counts.items()}\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'undefined': 1466, 'out': 590, 'in': 565, 'cross': 64}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_direction_info(bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overlap_undefined(df, offset_overlap, direction_type):\n",
    "    assert 'time_sec' in df.columns, \"DataFrame must include a 'time_sec' column.\"\n",
    "\n",
    "    df_copy = df.dropna(subset=['img_name']).copy()\n",
    "    # Filter rows where direction is In or Out and group by ID to find the min and max time_sec\n",
    "    grouped = df_copy[df_copy['direction'].isin(['In', 'Out'])].groupby('id').agg(\n",
    "        start=('time_sec', 'min'),\n",
    "        direction=('direction', 'first'),\n",
    "        end=('time_sec', 'max')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Expand the time window by the offset_overlap\n",
    "    grouped['start'] -= offset_overlap\n",
    "    grouped['end'] += offset_overlap\n",
    "\n",
    "    # Prepare the output dataframe\n",
    "    result = []\n",
    "\n",
    "    # Filter all undefined direction rows once for efficiency\n",
    "    # undefined_rows = df_copy[df_copy['direction'] == 'undefined']\n",
    "    undefined_rows = df_copy[df_copy['direction'].isin(direction_type)].groupby('id').agg(\n",
    "        start=('time_sec', 'min'),\n",
    "        direction=('direction', 'first'),\n",
    "        end=('time_sec', 'max')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Loop over each group and find overlaps with Undefined\n",
    "    for _, row in grouped.iterrows():\n",
    "        overlaps = undefined_rows[\n",
    "            (undefined_rows['start'] >= row['start']) & (undefined_rows['end'] <= row['end']) |\n",
    "            (undefined_rows['end'] >= row['start']) & (undefined_rows['end'] <= row['end']) |\n",
    "            (undefined_rows['start'] >= row['start']) & (undefined_rows['start'] <= row['end']) |\n",
    "            (row['start'] >= undefined_rows['start']) & (row['end'] <= undefined_rows['end'])\n",
    "        ]\n",
    "        for _, o_row in overlaps.iterrows():\n",
    "            if row['id'] == o_row['id']:\n",
    "                continue\n",
    "            overlap_type = ''\n",
    "            if o_row['start'] >= row['start'] and o_row['end'] <= row['end']:\n",
    "                overlap_type = 'inside'\n",
    "            elif o_row['end'] >= row['start'] and o_row['end'] <= row['end']:\n",
    "                overlap_type = 'start_overlap'\n",
    "            elif o_row['start'] >= row['start'] and o_row['start'] <= row['end']:\n",
    "                overlap_type = 'end_overlap'\n",
    "            elif row['start'] >= o_row['start'] and row['end'] <= o_row['end']:\n",
    "                overlap_type = 'suprass'\n",
    "            result.append({\n",
    "                'id': row['id'],\n",
    "                'direction': row['direction'],\n",
    "                'start_time': pd.to_datetime(row['start'], unit='s').time(),\n",
    "                'end_time': pd.to_datetime(row['end'], unit='s').time(),\n",
    "                'id_overlap': o_row['id'],\n",
    "                'direction_overlap': o_row['direction'],\n",
    "                'overlap_type': overlap_type,\n",
    "                'id_overlap_start_time': pd.to_datetime(o_row['start'], unit='s').time(),\n",
    "                'id_overlap_end_time': pd.to_datetime(o_row['end'], unit='s').time(),\n",
    "                'offset': offset_overlap,\n",
    "                'count' : len([value for _,value in overlaps.iterrows() if value['id'] != row['id']])\n",
    "            })\n",
    "\n",
    "    # Convert result to DataFrame\n",
    "    return pd.DataFrame(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_results = get_overlap_undefined(bbox, 0,['undefined'])\n",
    "overlap_results.to_csv('overlap_results_undefined.csv', index=False)\n",
    "\n",
    "overlap_results = get_overlap_undefined(bbox, 0,['In', 'Out'])\n",
    "overlap_results.to_csv('overlap_results_in_out.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "overlap_type\n",
       "inside           359\n",
       "start_overlap    201\n",
       "end_overlap      186\n",
       "suprass           76\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlap_results['overlap_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.to_csv('analysis.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info before: {'undefined': 1466, 'out': 590, 'in': 565, 'cross': 64}\n",
      "Info after: {'out': 590, 'in': 565, 'undefined': 456, 'cross': 64}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals = group_by_interval(filtered_df)\n",
    "total = count_ids_in_intervals(intervals)\n",
    "#print(total)\n",
    "\n",
    "with open('intervals.json', 'w') as f:\n",
    "\tf.write(str(intervals))\n",
    " \n",
    "with open('total.json', 'w') as f:\n",
    "\tf.write(str(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals[35750]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.to_csv('bbox_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_interval(df):\n",
    "    temp_df = df.dropna(subset=['img_name']).copy()\n",
    "    group = temp_df.groupby(['time_interval', 'id']).agg({'direction': 'first'}).reset_index()\n",
    "    \n",
    "    interval_dict = {}\n",
    "    for _, row in group.iterrows():\n",
    "        interval = row['time_interval']\n",
    "        if interval not in interval_dict:\n",
    "            interval_dict[interval] = {}\n",
    "        interval_dict[interval][row['id']] = {'direction': row['direction']}\n",
    "    return interval_dict\n",
    "\n",
    "# filter_interval_range_with_only_none\n",
    "def get_intervals_with_none(interval_dict):\n",
    "    none_intervals = {}\n",
    "    only_ids = set()\n",
    "    for interval, ids in interval_dict.items():\n",
    "        all_none = True\n",
    "        for id_info in ids.values():\n",
    "            if id_info['direction'] != 'undefined':\n",
    "                all_none = False\n",
    "                break\n",
    "        if all_none:\n",
    "            none_intervals[interval] = ids.copy()  # Create a copy of ids if ids itself is mutable\n",
    "            only_ids.update(ids.keys())\n",
    "    return none_intervals, only_ids\n",
    "\n",
    "def remove_ids_from_df(df, ids_to_remove):\n",
    "    # Use the `~` operator to select rows where 'id' is not in 'ids_to_remove'\n",
    "    filtered_df = df[~df['id'].isin(ids_to_remove)].copy()  # Explicitly copying is optional here since filtering creates a new df\n",
    "    return filtered_df\n",
    "\n",
    "def count_ids_in_intervals(interval_dict):\n",
    "    interval_counts = {interval: len(ids) for interval, ids in interval_dict.items()}\n",
    "    sorted_interval_counts = dict(sorted(interval_counts.items(), key=lambda item: item[1], reverse=True))\n",
    "    return sorted_interval_counts\n",
    "\n",
    "info_before = get_direction_info(bbox)\n",
    "print(f\"Info before: {info_before}\")\n",
    "df = add_column_time_interval(bbox, interval_sec=5, frame_rate=15)\n",
    "result = group_by_interval(df)\n",
    "intervals_keys,ids = get_intervals_with_none(result)\n",
    "filtered_df = remove_ids_from_df(df, ids)\n",
    "info_after = get_direction_info(filtered_df)\n",
    "print(f\"Info after: {info_after}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
