{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import datetime\n",
    "import os\n",
    "import base64\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import sqlite3\n",
    "from utils.pipeline import get_files\n",
    "from utils.tools import seconds_to_time\n",
    "# Set the maximum number of rows and columns to display\n",
    "pd.set_option('display.max_rows', 1000)  # Adjust the number as needed\n",
    "pd.set_option('display.max_columns', 1000)  # Adjust the number as needed\n",
    "\n",
    "files = get_files('/home/diego/Documents/yolov7-tracker/runs/detect/2024_04_17_conce_bytetrack')\n",
    "db = files['db']\n",
    "\n",
    "conn = sqlite3.connect(db)\n",
    "cursor = conn.cursor()    \n",
    "bbox = pd.read_sql('SELECT * FROM bbox_raw', conn)\n",
    "bbox['direction'] = bbox.apply(lambda row: ('undefined' if row['img_name'].split('_')[3] == 'None' else  row['img_name'].split('_')[3]) if row['img_name'] is not None else None, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_direction_info(df):\n",
    "    # Using .copy() to ensure the original dataframe is not affected\n",
    "    temp_df = df.copy()\n",
    "    first_directions = temp_df.groupby('id')['direction'].first().reset_index()\n",
    "    direction_counts = first_directions['direction'].value_counts().to_dict()\n",
    "    result = {k.lower(): v for k, v in direction_counts.items()}\n",
    "    return result\n",
    "\n",
    "def add_column_time_interval(df, interval_sec, frame_rate):\n",
    "    df_copy = df.copy()\n",
    "    frames_per_interval = interval_sec * frame_rate\n",
    "    df_copy['time_interval'] = (df_copy['frame_number'] // frames_per_interval) * interval_sec\n",
    "    df_copy['time_video'] = df_copy['time_interval'].apply(seconds_to_time)\n",
    "    return df_copy\n",
    "\n",
    "def analysis_by_interval(df):\n",
    "    # Assert that 'time_interval' column exists in the DataFrame\n",
    "    assert 'time_interval' in df.columns, \"DataFrame must include a 'time_interval' column.\"\n",
    "    \n",
    "    # Filter rows where 'img_name' is not NaN to consider only valid images\n",
    "    valid_rows = df.dropna(subset=['img_name']).copy()\n",
    "    \n",
    "    # Group by 'time_interval' and 'id' and get the first 'direction' for each group\n",
    "    grouped = valid_rows.groupby(['time_interval', 'id']).agg({\n",
    "        'direction': 'first',  # First direction found for the group\n",
    "        'time_video': 'first'  # First time_video found for the group (assuming all entries per group are the same)\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Calculate the total number of IDs per interval\n",
    "    total_counts = valid_rows.groupby('time_interval')['id'].nunique().to_dict()\n",
    "\n",
    "    \n",
    "    # Prepare the final DataFrame\n",
    "    final_df = grouped.copy()\n",
    "    final_df['total'] = final_df['time_interval'].apply(lambda x: total_counts[x])\n",
    "    final_df['all_undefined'] = final_df.groupby('time_interval')['direction'].transform(lambda x: all(d == 'undefined' for d in x))\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_with_interval = add_column_time_interval(bbox, 5, 15)\n",
    "analysis = analysis_by_interval(bbox_with_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_direction_info(bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.to_csv('analysis.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info before: {'undefined': 1466, 'out': 590, 'in': 565, 'cross': 64}\n",
      "Info after: {'out': 590, 'in': 565, 'undefined': 456, 'cross': 64}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals = group_by_interval(filtered_df)\n",
    "total = count_ids_in_intervals(intervals)\n",
    "#print(total)\n",
    "\n",
    "with open('intervals.json', 'w') as f:\n",
    "\tf.write(str(intervals))\n",
    " \n",
    "with open('total.json', 'w') as f:\n",
    "\tf.write(str(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals[35750]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.to_csv('bbox_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_interval(df):\n",
    "    temp_df = df.dropna(subset=['img_name']).copy()\n",
    "    group = temp_df.groupby(['time_interval', 'id']).agg({'direction': 'first'}).reset_index()\n",
    "    \n",
    "    interval_dict = {}\n",
    "    for _, row in group.iterrows():\n",
    "        interval = row['time_interval']\n",
    "        if interval not in interval_dict:\n",
    "            interval_dict[interval] = {}\n",
    "        interval_dict[interval][row['id']] = {'direction': row['direction']}\n",
    "    return interval_dict\n",
    "\n",
    "# filter_interval_range_with_only_none\n",
    "def get_intervals_with_none(interval_dict):\n",
    "    none_intervals = {}\n",
    "    only_ids = set()\n",
    "    for interval, ids in interval_dict.items():\n",
    "        all_none = True\n",
    "        for id_info in ids.values():\n",
    "            if id_info['direction'] != 'undefined':\n",
    "                all_none = False\n",
    "                break\n",
    "        if all_none:\n",
    "            none_intervals[interval] = ids.copy()  # Create a copy of ids if ids itself is mutable\n",
    "            only_ids.update(ids.keys())\n",
    "    return none_intervals, only_ids\n",
    "\n",
    "def remove_ids_from_df(df, ids_to_remove):\n",
    "    # Use the `~` operator to select rows where 'id' is not in 'ids_to_remove'\n",
    "    filtered_df = df[~df['id'].isin(ids_to_remove)].copy()  # Explicitly copying is optional here since filtering creates a new df\n",
    "    return filtered_df\n",
    "\n",
    "def count_ids_in_intervals(interval_dict):\n",
    "    interval_counts = {interval: len(ids) for interval, ids in interval_dict.items()}\n",
    "    sorted_interval_counts = dict(sorted(interval_counts.items(), key=lambda item: item[1], reverse=True))\n",
    "    return sorted_interval_counts\n",
    "\n",
    "info_before = get_direction_info(bbox)\n",
    "print(f\"Info before: {info_before}\")\n",
    "df = add_column_time_interval(bbox, interval_sec=5, frame_rate=15)\n",
    "result = group_by_interval(df)\n",
    "intervals_keys,ids = get_intervals_with_none(result)\n",
    "filtered_df = remove_ids_from_df(df, ids)\n",
    "info_after = get_direction_info(filtered_df)\n",
    "print(f\"Info after: {info_after}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
