{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import datetime\n",
    "import os\n",
    "import base64\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import sqlite3\n",
    "from utils.pipeline import get_files\n",
    "from utils.data_analysis import get_overlap_undefined,get_direction_info\n",
    "from utils.types import Direction\n",
    "# Set the maximum number of rows and columns to display\n",
    "pd.set_option('display.max_rows', 1000)  # Adjust the number as needed\n",
    "pd.set_option('display.max_columns', 1000)  # Adjust the number as needed\n",
    "\n",
    "files = get_files('/home/diego/Documents/yolov7-tracker/runs/detect/2024_04_17_conce_bytetrack')\n",
    "db = files['db']\n",
    "FRAME_NUMBER = 15\n",
    "conn = sqlite3.connect(db)\n",
    "bbox = pd.read_sql('SELECT * FROM bbox_raw', conn)\n",
    "bbox['direction'] = bbox.apply(lambda row: ('undefined' if row['img_name'].split('_')[3] == 'None' else  row['img_name'].split('_')[3]) if row['img_name'] is not None else None, axis=1)\n",
    "bbox['time_sec'] = bbox.apply(lambda row: int(row['frame_number']) // FRAME_NUMBER, axis=1)\n",
    "bbox['time_video'] = pd.to_datetime(bbox['time_sec'], unit='s').dt.time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from scipy.stats import linregress\n",
    "\n",
    "\n",
    "def create_plot(df, primary_id,unique_ids, intersecting_id_colors=['green', 'orange', 'purple', 'cyan', 'magenta', 'yellow', 'brown']):\n",
    "    slopes = {}\n",
    "    for unique_id in unique_ids:\n",
    "        id_data = df[df['id'] == unique_id]\n",
    "        slope, intercept, r_value, p_value, std_err = linregress(id_data['frame_number'], id_data['distance_to_center'])\n",
    "        slopes[unique_id] = slope\n",
    "        \n",
    "    reference_slope = slopes[primary_id]  # You need to define this\n",
    "    normalized_slopes = {unique_id: slope / reference_slope for unique_id, slope in slopes.items()}\n",
    "    \n",
    "    \n",
    "    \n",
    "    scaled_slopes = {}\n",
    "    for unique_id in unique_ids:\n",
    "        id_data = df[df['id'] == unique_id]\n",
    "        min_y = id_data['distance_to_center'].min()\n",
    "        max_y = id_data['distance_to_center'].max()\n",
    "        scaled_slopes[unique_id] = (slopes[unique_id] - min_y) / (max_y - min_y) if max_y != min_y else 0\n",
    "    \n",
    "    \n",
    "    standardized_slopes = {}\n",
    "    for unique_id in unique_ids:\n",
    "        id_data = df[df['id'] == unique_id]\n",
    "        mean_y = id_data['distance_to_center'].mean()\n",
    "        std_y = id_data['distance_to_center'].std()\n",
    "        standardized_slopes[unique_id] = (slopes[unique_id] - mean_y) / std_y if std_y != 0 else 0\n",
    "\n",
    "    \n",
    "    \n",
    "    # Create the figure and axis objects\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))  # You can adjust the size as needed\n",
    "\n",
    "    # Filter the dataframe for the primary ID and sort it\n",
    "    df_primary_id = df[df['id'] == primary_id].sort_values(by='frame_number')\n",
    "\n",
    "    # Scatter plot for the primary ID with different colors for positive and negative distances\n",
    "    positive_distance = df_primary_id['distance_to_center'] > 0\n",
    "    ax.scatter(df_primary_id[positive_distance]['frame_number'], df_primary_id[positive_distance]['distance_to_center'],c='blue', s=10, alpha=0.6, label=f'ID {primary_id} In')\n",
    "    ax.scatter(df_primary_id[~positive_distance]['frame_number'], df_primary_id[~positive_distance]['distance_to_center'],c='red', s=10, alpha=0.6, label=f'ID {primary_id} Out')\n",
    "\n",
    "    # Calculate the time frame start and end\n",
    "    timeframe_start = df['frame_number'].min()\n",
    "    timeframe_end = df['frame_number'].max()\n",
    "\n",
    "    # Identify other intersecting IDs within this timeframe\n",
    "    intersecting_ids = df[(df['frame_number'] >= timeframe_start) & (df['frame_number'] <= timeframe_end) &  (df['id'] != primary_id)]['id'].unique()\n",
    "\n",
    "    # Plot data for each intersecting ID within the timeframe\n",
    "    for idx, other_id in enumerate(intersecting_ids):\n",
    "        df_other_id = df[(df['id'] == other_id) &  (df['frame_number'] >= timeframe_start) &  (df['frame_number'] <= timeframe_end)]\n",
    "        color = intersecting_id_colors[idx % len(intersecting_id_colors)]\n",
    "        ax.scatter(df_other_id['frame_number'], df_other_id['distance_to_center'], c=color, s=20, edgecolor='k', label=f'ID {other_id}')\n",
    "    \n",
    "    # Plot formatting\n",
    "    ax.axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
    "    ax.set_xlim(timeframe_start - 10, timeframe_end + 10)  # A little space around the edges\n",
    "    ax.set_ylim(df['distance_to_center'].min() - 10, df['distance_to_center'].max() + 10)\n",
    "\n",
    "    # Construct the title to include the ID and its timeframe\n",
    "    duration = timeframe_end - timeframe_start\n",
    "    title_text = f'ID {primary_id}: #{duration} '\n",
    "    ax.set_title(title_text, color='red')\n",
    "\n",
    "    ax.set_xlabel('Frame Number')\n",
    "    ax.set_ylabel('Distance to Center')\n",
    "    ax.legend(loc='upper left', fontsize='small')\n",
    "    slopes_text = ', '.join([f'{key}: {value:.3f}' for key, value in slopes.items()])\n",
    "    fig.text(0.5, 1, f\"{slopes_text} = slopes\", ha='center', va='center', fontsize=10, color='green', style='italic')  # Adjust the position and style as needed\n",
    "    \n",
    "    normalized_slopes_text = ', '.join([f'{key}: {value:.3f}' for key, value in normalized_slopes.items()])\n",
    "    fig.text(0.5, -0.02, f\"{normalized_slopes_text} = normalized\", ha='center', va='center', fontsize=10, color='blue', style='italic')  # Adjust the position and style as needed\n",
    "    \n",
    "    scaled_slopes_text = ', '.join([f'{key}: {value:.3f}' for key, value in scaled_slopes.items()])\n",
    "    fig.text(0.5, -0.05, f\"{scaled_slopes_text} = scaled\", ha='center', va='center', fontsize=10, color='blue', style='italic')  # Adjust the position and style as needed\n",
    "    \n",
    "    standardized_slopes_text = ', '.join([f'{key}: {value:.3f}' for key, value in standardized_slopes.items()])\n",
    "    fig.text(0.5, -0.08, f\"{standardized_slopes_text} = standardized\", ha='center', va='center', fontsize=10, color='blue', style='italic')  # Adjust the position and style as needed\n",
    "    \n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "import seaborn as sns\n",
    "\n",
    "query = 'SELECT * FROM overlap_results WHERE count = 1'\n",
    "overlap_results = pd.read_sql(query, conn)\n",
    "\n",
    "ids_overlap = list(overlap_results['id_overlap'])\n",
    "query = 'SELECT id, distance_to_center, frame_number FROM bbox_raw WHERE id IN ({})'.format(', '.join(['?']*len(ids_overlap)))\n",
    "bboxes = pd.read_sql(query, conn, params=ids_overlap)\n",
    "\n",
    "def calculate_similarity(df, ids):\n",
    "    correlation_matrix = np.zeros((len(ids), len(ids)))\n",
    "    \n",
    "    for i, id1 in enumerate(ids):\n",
    "        for j, id2 in enumerate(ids):\n",
    "            if i >= j:\n",
    "                continue\n",
    "            series1 = df[df['id'] == id1]['distance_to_center'].values\n",
    "            series2 = df[df['id'] == id2]['distance_to_center'].values\n",
    "            \n",
    "            # Make series the same length\n",
    "            min_length = min(len(series1), len(series2))\n",
    "            series1 = series1[:min_length]\n",
    "            series2 = series2[:min_length]\n",
    "            \n",
    "            # Calculate Pearson Correlation Coefficient\n",
    "            corr, _ = pearsonr(series1, series2)\n",
    "            correlation_matrix[i, j] = corr\n",
    "            correlation_matrix[j, i] = corr  # Matrix is symmetrical\n",
    "    \n",
    "    return correlation_matrix\n",
    "\n",
    "# Usage:\n",
    "# ids_overlap could be a list of all unique ids you want to compare\n",
    "similarity_matrix = calculate_similarity(bboxes, ids_overlap)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.spatial.distance import euclidean\n",
    "from fastdtw import fastdtw\n",
    "\n",
    "primary_id = 3625\n",
    "query = 'SELECT * FROM overlap_results'\n",
    "overlap_results = pd.read_sql(query, conn)\n",
    "\n",
    "overlap_results_only_id = overlap_results[overlap_results['id'] == primary_id]\n",
    "ids_overlap = list(overlap_results_only_id['id_overlap'])\n",
    "ids_overlap.append(primary_id)  # Append the integer version of id\n",
    "\n",
    "query = 'SELECT id, distance_to_center, frame_number FROM bbox_raw WHERE  id IN ({})'.format(', '.join(['?']*len(ids_overlap)))\n",
    "bbox2 = pd.read_sql(query, conn, params=ids_overlap)\n",
    "\n",
    "\n",
    "def compare_two_curves(id1, id2, df):\n",
    "    # Extract the series for the two IDs\n",
    "    series1 = df[df['id'] == id1][['frame_number', 'distance_to_center']].sort_values('frame_number')\n",
    "    series2 = df[df['id'] == id2][['frame_number', 'distance_to_center']].sort_values('frame_number')\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    series1 = series1.to_numpy()\n",
    "    series2 = series2.to_numpy()\n",
    "\n",
    "    # Apply DTW\n",
    "    distance, path = fastdtw(series1, series2, dist=euclidean)\n",
    "    \n",
    "    return distance, path\n",
    "\n",
    "# Replace 'id1' and 'id2' with the actual IDs you want to compare\n",
    "id1 = ids_overlap[0]  # Replace with the first ID you want to compare\n",
    "id2 = ids_overlap[1]  # Replace with the second ID you want to compare\n",
    "\n",
    "# Use the compare_two_curves function\n",
    "dtw_distance, dtw_path = compare_two_curves(id1, id2, bbox2)\n",
    "\n",
    "print(f\"DTW distance between ID {id1} and ID {id2}: {dtw_distance}\")\n",
    "\n",
    "\n",
    "#plot_path = create_plot(bbox2,primary_id, ids_overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standarizar todas las pentiednes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### NUEVO #### \n",
    "\n",
    "from scipy.stats import linregress\n",
    "\n",
    "# Assuming 'bbox2' is loaded with the relevant data\n",
    "query = 'SELECT id, distance_to_center, frame_number FROM bbox_raw'\n",
    "bbox2 = pd.read_sql(query, conn)\n",
    "# 1. Calculate slopes for each ID\n",
    "slopes = {}\n",
    "for id_group, group_data in bbox2.groupby('id'):\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(group_data['frame_number'], group_data['distance_to_center'])\n",
    "    slopes[id_group] = slope\n",
    "\n",
    "\n",
    "valid_slopes = {k: v for k, v in slopes.items() if not np.isnan(v)}\n",
    "valid_slopes2 = {k: v for k, v in slopes.items() if np.isnan(v)}\n",
    "average_slope = sum(valid_slopes.values()) / len(valid_slopes)\n",
    "normalized_slopes = {id_group: slope / average_slope for id_group, slope in slopes.items()}\n",
    "valid_slopes2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter undefined logic 1 count - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_overlap_total = overlap_results[overlap_results['count'] == 1]['id_overlap'].unique().tolist()\n",
    "\n",
    "query = 'SELECT id, distance_to_center, frame_number FROM bbox_raw WHERE id IN ({})'.format(', '.join(['?']*len(ids_overlap_total)))\n",
    "\n",
    "bbox_overlap = pd.read_sql(query, conn, params=ids_overlap_total)\n",
    "\n",
    "df = bbox_overlap.sort_values(by=['id', 'frame_number'])\n",
    "df['previous_distance_to_center'] = df.groupby('id')['distance_to_center'].shift(1)\n",
    "crosses_zero = df.apply(lambda row: (row['distance_to_center'] < 0 < row['previous_distance_to_center']) or (row['distance_to_center'] > 0 > row['previous_distance_to_center']), axis=1)\n",
    "ids_crossing_zero = df[crosses_zero]['id'].unique()\n",
    "\n",
    "overlap_results[overlap_results['id_overlap'].isin(ids_crossing_zero)]['id'].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### None Analysis 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.spatial.distance import euclidean\n",
    "from fastdtw import fastdtw\n",
    "\n",
    "#primary_id = 2469\n",
    "count_overlaps = 1\n",
    "query = \"\"\"\n",
    "    SELECT\n",
    "    or2.id as base_id, \n",
    "    br.id,\n",
    "    CASE WHEN or2.id = br.id THEN 1 ELSE 0 END as primary_id, \n",
    "    or2.id_overlap,\n",
    "    br.frame_number,\n",
    "    br.distance_to_center,\n",
    "    or2.count,\n",
    "    or2.direction\n",
    "FROM \n",
    "    overlap_results AS or2 \n",
    "LEFT JOIN \n",
    "    bbox_raw AS br ON br.id = or2.id OR br.id = or2.id_overlap \n",
    "WHERE \n",
    "    or2.count = ?\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "bbox_analysis = pd.read_sql(query, conn, params=(count_overlaps,))\n",
    "\n",
    "\n",
    "\n",
    "## Only the id that got primary_id = 1 must be in the top level of the dictionary, and for every id that got primary_id = 1 must be a id_overlap associate it with\n",
    "\n",
    "# {\n",
    "# \tprimary_id : {\n",
    "# \t\tdirection : 'In',\n",
    "# \t\tdata : [{frame_number: 1, distance_to_center: 10}, {frame_number: 2, distance_to_center: 20}]\n",
    "# \t\tid_overlap : {\n",
    "# \t\t\t1 : {\n",
    "# \t\t\t\tdirection : 'Undefined',\n",
    "# \t\t\t\tdata : [{frame_number: 1, distance_to_center: 10}, {frame_number: 2, distance_to_center: 20}]\n",
    "# \t\t\t}\n",
    "# \t\t}\n",
    "# \t}\n",
    "# }\n",
    "\n",
    "#create_plot(bbox_analysis,primary_id, bbox_analysis['id'].unique().tolist())\n",
    "\n",
    "\n",
    "# from scipy.stats import linregress\n",
    "\n",
    "# for id_group, group_data in bbox_analysis[bbox_analysis['direction'] == 'In'].groupby('id'):\n",
    "#     slope, intercept, r_value, p_value, std_err = linregress(group_data['frame_number'], group_data['distance_to_center'])\n",
    "#     slopes[id_group] = slope\n",
    "\n",
    "\n",
    "# valid_slopes = {k: v for k, v in slopes.items() if not np.isnan(v)}\n",
    "# #valid_slopes2 = {k: v for k, v in slopes.items() if np.isnan(v)}\n",
    "# average_slope = sum(valid_slopes.values()) / len(valid_slopes)\n",
    "# normalized_slopes = {id_group: slope / average_slope for id_group, slope in slopes.items()}\n",
    "# normalized_slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No overlap in ID: 618\n",
      "No overlap in ID: 876\n",
      "No overlap in ID: 1169\n",
      "No overlap in ID: 1247\n",
      "No overlap in ID: 1434\n",
      "No overlap in ID: 1607\n",
      "No overlap in ID: 1705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/miniconda3/lib/python3.11/site-packages/scipy/stats/_stats_mstats_common.py:182: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  slope = ssxym / ssxm\n",
      "/home/diego/miniconda3/lib/python3.11/site-packages/scipy/stats/_stats_mstats_common.py:196: RuntimeWarning: invalid value encountered in sqrt\n",
      "  t = r * np.sqrt(df / ((1.0 - r + TINY)*(1.0 + r + TINY)))\n",
      "/home/diego/miniconda3/lib/python3.11/site-packages/scipy/stats/_stats_mstats_common.py:199: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  slope_stderr = np.sqrt((1 - r**2) * ssym / ssxm / df)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No overlap in ID: 2214\n",
      "No overlap in ID: 2700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/miniconda3/lib/python3.11/site-packages/scipy/stats/_stats_mstats_common.py:182: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  slope = ssxym / ssxm\n",
      "/home/diego/miniconda3/lib/python3.11/site-packages/scipy/stats/_stats_mstats_common.py:196: RuntimeWarning: invalid value encountered in sqrt\n",
      "  t = r * np.sqrt(df / ((1.0 - r + TINY)*(1.0 + r + TINY)))\n",
      "/home/diego/miniconda3/lib/python3.11/site-packages/scipy/stats/_stats_mstats_common.py:199: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  slope_stderr = np.sqrt((1 - r**2) * ssym / ssxm / df)\n",
      "/home/diego/miniconda3/lib/python3.11/site-packages/scipy/stats/_stats_mstats_common.py:182: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  slope = ssxym / ssxm\n",
      "/home/diego/miniconda3/lib/python3.11/site-packages/scipy/stats/_stats_mstats_common.py:196: RuntimeWarning: invalid value encountered in sqrt\n",
      "  t = r * np.sqrt(df / ((1.0 - r + TINY)*(1.0 + r + TINY)))\n",
      "/home/diego/miniconda3/lib/python3.11/site-packages/scipy/stats/_stats_mstats_common.py:199: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  slope_stderr = np.sqrt((1 - r**2) * ssym / ssxm / df)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No overlap in ID: 4404\n",
      "No overlap in ID: 4554\n",
      "No overlap in ID: 5782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/miniconda3/lib/python3.11/site-packages/scipy/stats/_stats_mstats_common.py:182: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  slope = ssxym / ssxm\n",
      "/home/diego/miniconda3/lib/python3.11/site-packages/scipy/stats/_stats_mstats_common.py:196: RuntimeWarning: invalid value encountered in sqrt\n",
      "  t = r * np.sqrt(df / ((1.0 - r + TINY)*(1.0 + r + TINY)))\n",
      "/home/diego/miniconda3/lib/python3.11/site-packages/scipy/stats/_stats_mstats_common.py:199: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  slope_stderr = np.sqrt((1 - r**2) * ssym / ssxm / df)\n",
      "/home/diego/miniconda3/lib/python3.11/site-packages/scipy/stats/_stats_mstats_common.py:182: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  slope = ssxym / ssxm\n",
      "/home/diego/miniconda3/lib/python3.11/site-packages/scipy/stats/_stats_mstats_common.py:196: RuntimeWarning: invalid value encountered in sqrt\n",
      "  t = r * np.sqrt(df / ((1.0 - r + TINY)*(1.0 + r + TINY)))\n",
      "/home/diego/miniconda3/lib/python3.11/site-packages/scipy/stats/_stats_mstats_common.py:199: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  slope_stderr = np.sqrt((1 - r**2) * ssym / ssxm / df)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No overlap in ID: 6227\n",
      "No overlap in ID: 6972\n",
      "No overlap in ID: 7300\n",
      "No overlap in ID: 7311\n",
      "No overlap in ID: 8032\n"
     ]
    }
   ],
   "source": [
    "structured_data = {}\n",
    "data_slope = []\n",
    "\n",
    "# Group the dataframe by 'base_id' to process each primary_id group\n",
    "for base_id, group in bbox_analysis.groupby('base_id'):\n",
    "    primary_data = group[group['primary_id'] == 1]\n",
    "    overlap_data = group[group['primary_id'] == 0]\n",
    "\n",
    "    # Get the minimum and maximum frame numbers for the undefined curve\n",
    "    min_time_frame_undefined_curve = overlap_data['frame_number'].min()\n",
    "    max_time_frame_undefined_curve = overlap_data['frame_number'].max()\n",
    "    \n",
    "    # Filter for overlap only when primary_id == 1 within the frame number range of the undefined curve\n",
    "    only_overlap = primary_data[\n",
    "        (primary_data['frame_number'] >= min_time_frame_undefined_curve) & \n",
    "        (primary_data['frame_number'] <= max_time_frame_undefined_curve)\n",
    "    ]\n",
    "\n",
    "    if only_overlap.empty:\n",
    "        print('No overlap in ID:', base_id)\n",
    "        continue\n",
    "\n",
    "    # Calculate slope for only_overlap\n",
    "    slope_primary = linregress(only_overlap['frame_number'], only_overlap['distance_to_center']).slope\n",
    "    \n",
    "    # Calculate slope for overlap_data\n",
    "    slope_overlap = linregress(overlap_data['frame_number'], overlap_data['distance_to_center']).slope\n",
    "    \n",
    "    # Store the structured data\n",
    "    structured_data[base_id] = {\n",
    "        'direction': group['direction'].iloc[0],\n",
    "        'data': only_overlap.to_dict('records'),\n",
    "        'only_overlap': only_overlap.to_dict('records'),\n",
    "        'slope': slope_primary,\n",
    "        'id_overlap': {\n",
    "            'direction': 'Undefined',\n",
    "            'data': overlap_data.to_dict('records'),\n",
    "            'slope': slope_overlap\n",
    "        }\n",
    "    }\n",
    "    data_slope.append((base_id, overlap_data['id_overlap'].iloc[0], slope_primary, slope_overlap, abs(slope_primary - slope_overlap)))\n",
    "\n",
    "data_slope_df = pd.DataFrame(data_slope, columns=['primary_id', 'id_overlap', 'slope_primary', 'slope_overlap', 'diff_slope'])\n",
    "# Now you can use data_slope_df as a DataFrame\n",
    "data_slope_df.to_csv('data_slope.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(structured_data[3625]['slope'],structured_data[3625]['id_overlap']['slope'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_data[2469]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_analysis.head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_analysis[bbox_analysis['direction'] == 'In'].groupby('id')['id'].count().__len__()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
