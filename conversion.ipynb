{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "HOST, ADMIN, PASS, DB =  'mivo-db.cj2ucwgierrs.us-east-1.rds.amazonaws.com', 'admin', '58#64KDashz^bLrqTG2', 'mivo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dtype_spec = {\n",
    "    'Tipo': 'int',\n",
    "    'Numero': 'int',\n",
    "    'Lin': 'int',\n",
    "    'C.Bod': 'int',\n",
    "    'Cant': 'int',\n",
    "    'Venta': 'int',\n",
    "    'Costo': 'int',\n",
    "    'Margen': 'int',\n",
    "    'Jerarquia': str,\n",
    "    'Sub Jerarquia': str,\n",
    "    'Local': str,\n",
    "    'Color': str,\n",
    "    'talla': str,\n",
    "    'Marca': str,\n",
    "    'temporada': str,\n",
    "    'Rut': str,\n",
    "    'Cliente': str\n",
    "}\n",
    "df = pd.read_csv('Ventas.csv', usecols=list(dtype_spec.keys()) + ['Fecha'], dtype=dtype_spec)\n",
    "df['Fecha'] = pd.to_datetime(df['Fecha'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Local'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flujo = pd.read_csv('Flujo.csv')\n",
    "flujo['FECHA'] = pd.to_datetime(flujo['FECHA'], format='%m/%d/%Y')\n",
    "flujo['Total Visitas'] = flujo.iloc[:, 2:26].sum(axis=1)\n",
    "flujoSimple = flujo[['FECHA','ENTRADA', 'Total Visitas']]\n",
    "flujoSimple.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data types for the hourly columns from 00 to 23\n",
    "hour_columns_dtypes = {f\"{hour:02}\": int for hour in range(24)}\n",
    "\n",
    "# 'ENTRADA' is specified as a string\n",
    "dtype_dict = {\n",
    "    'ENTRADA': str,\n",
    "    **hour_columns_dtypes  # Merge the dictionary with hourly data types\n",
    "}\n",
    "\n",
    "# Load the CSV file with defined data types and specify 'FECHA' as a date column\n",
    "traffic_df = pd.read_csv('Flujo.csv', dtype=dtype_dict, parse_dates=['FECHA'])\n",
    "\n",
    "# Display the first few entries to check data loading\n",
    "print(traffic_df.head())\n",
    "\n",
    "# Check the data types to confirm proper loading and type assignment\n",
    "#print(traffic_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is already loaded and contains your sales data\n",
    "\n",
    "# Ensure 'Fecha' is a datetime type for proper grouping\n",
    "df['Fecha'] = pd.to_datetime(df['Fecha'])\n",
    "\n",
    "# Group by 'Fecha' and 'Local', and count distinct 'Numero'\n",
    "daily_sales = df.groupby(['Fecha', 'Local']).agg(purchases=('Numero', 'nunique')).reset_index()\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(daily_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits = pd.DataFrame(flujoSimple)\n",
    "sales = pd.DataFrame(daily_sales)\n",
    "\n",
    "# Normalize the date columns\n",
    "visits['FECHA'] = pd.to_datetime(visits['FECHA'])\n",
    "sales['Fecha'] = pd.to_datetime(sales['Fecha'])\n",
    "\n",
    "\n",
    "# Normalize the local/entrada names to lowercase\n",
    "visits['ENTRADA'] = visits['ENTRADA'].astype(str).str.lower().str.strip()\n",
    "sales['Local'] = sales['Local'].astype(str).str.lower().str.strip()\n",
    "\n",
    "# Rename columns for consistency\n",
    "visits.rename(columns={'FECHA': 'date', 'ENTRADA': 'local'}, inplace=True)\n",
    "sales.rename(columns={'Fecha': 'date', 'Local': 'local'}, inplace=True)\n",
    "\n",
    "# Merge DataFrames\n",
    "result = pd.merge(visits, sales, on=['date', 'local'], how='inner')\n",
    "result['conversion_rate'] = result['purchases'] / result['Total Visitas'] * 100\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dtype_spec = {\n",
    "    'Tipo': 'int',\n",
    "    'Numero': 'int',\n",
    "    'Lin': 'int',\n",
    "    'C.Bod': 'int',\n",
    "    'Cant': 'int',\n",
    "    'Venta': 'int',\n",
    "    'Costo': 'int',\n",
    "    'Margen': 'int',\n",
    "    'Jerarquia': str,\n",
    "    'Sub Jerarquia': str,\n",
    "    'Local': str,\n",
    "    'Color': str,\n",
    "    'talla': str,\n",
    "    'Marca': str,\n",
    "    'temporada': str,\n",
    "    'Rut': str,\n",
    "    'Cliente': str\n",
    "}\n",
    "ventas = pd.read_csv('Ventas.csv', usecols=list(dtype_spec.keys()) + ['Fecha'], dtype=dtype_spec)\n",
    "ventas['Fecha'] = pd.to_datetime(ventas['Fecha'], format='%Y%m%d')\n",
    "daily_sales = ventas.groupby(['Fecha', 'Local']).agg(purchases=('Numero', 'nunique')).reset_index()\n",
    "# clients_sales = ventas.groupby(['Cliente']).agg(\n",
    "#     Total_Venta=('Venta', 'sum'),\n",
    "#     Item_Count=('Numero', 'nunique'),\n",
    "#     ).reset_index()\n",
    "\n",
    "\n",
    "flujo = pd.read_csv('Flujo.csv')\n",
    "flujo['FECHA'] = pd.to_datetime(flujo['FECHA'], format='%m/%d/%Y')\n",
    "flujo['Total Visitas'] = flujo.iloc[:, 2:26].sum(axis=1)\n",
    "flujoSimple = flujo[['FECHA','ENTRADA', 'Total Visitas']]\n",
    "\n",
    "visits = pd.DataFrame(flujoSimple)\n",
    "sales = pd.DataFrame(daily_sales)\n",
    "\n",
    "# Normalize the date columns\n",
    "visits['FECHA'] = pd.to_datetime(visits['FECHA'])\n",
    "sales['Fecha'] = pd.to_datetime(sales['Fecha'])\n",
    "\n",
    "\n",
    "# Normalize the local/entrada names to lowercase\n",
    "visits['ENTRADA'] = visits['ENTRADA'].astype(str).str.lower().str.strip()\n",
    "sales['Local'] = sales['Local'].astype(str).str.lower().str.strip()\n",
    "\n",
    "# Rename columns for consistency\n",
    "visits.rename(columns={'FECHA': 'date', 'ENTRADA': 'local'}, inplace=True)\n",
    "sales.rename(columns={'Fecha': 'date', 'Local': 'local'}, inplace=True)\n",
    "\n",
    "# Merge DataFrames\n",
    "result = pd.merge(visits, sales, on=['date', 'local'], how='inner')\n",
    "result['conversion_rate'] = result['purchases'] / result['Total Visitas'] * 100\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert sales to DB [WORKING]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "\n",
    "dtype_spec = {\n",
    "    'Tipo': 'int',\n",
    "    'Numero': 'int',\n",
    "    'Lin': 'int',\n",
    "    'C.Bod': 'int',\n",
    "    'Cant': 'int',\n",
    "    'Venta': 'int',\n",
    "    'Costo': 'int',\n",
    "    'Margen': 'int',\n",
    "    'Jerarquia': str,\n",
    "    'Sub Jerarquia': str,\n",
    "    'Local': str,\n",
    "    'Color': str,\n",
    "    'talla': str,\n",
    "    'Marca': str,\n",
    "    'temporada': str,\n",
    "    'Rut': str,\n",
    "    'Cliente': str\n",
    "}\n",
    "ventas = pd.read_csv('Ventas.csv', usecols=list(dtype_spec.keys()) + ['Fecha'], dtype=dtype_spec)\n",
    "ventas['Fecha'] = pd.to_datetime(ventas['Fecha'], format='%Y%m%d')\n",
    "daily_sales = ventas.groupby(['Fecha', 'Local']).agg(purchases=('Numero', 'nunique')).reset_index()\n",
    "\n",
    "\n",
    "sales = pd.DataFrame(daily_sales)\n",
    "\n",
    "\n",
    "## Only some stores\n",
    "salesFiltered = pd.DataFrame(sales)\n",
    "\n",
    "# Mapping dictionary\n",
    "local_map = {\n",
    "    'concepcion': 1,\n",
    "    'santos dumontt': 2,\n",
    "    'mall tobalaba pte.alto': 3,\n",
    "    'mall quilin': 4\n",
    "}\n",
    "\n",
    "# Apply the map to the 'local' column\n",
    "salesFiltered['store_id'] = salesFiltered['local'].map(local_map).astype('Int64')\n",
    "\n",
    "# Filter out rows where 'mapped_value' is None\n",
    "filtered_sales = salesFiltered.dropna(subset=['store_id'])\n",
    "\n",
    "# Print the filtered DataFrame\n",
    "filtered_sales.head()\n",
    "\n",
    "\n",
    "\n",
    "conn = pymysql.connect(host=HOST, user=ADMIN, password=PASS, database=DB)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "insert_query = \"\"\"\n",
    "INSERT INTO sales (purchases, date, store_id)\n",
    "VALUES (%s, %s, %s);\n",
    "\"\"\"\n",
    "\n",
    "# Iterate over DataFrame rows\n",
    "for index, row in filtered_sales.iterrows():\n",
    "    # Here you might add checks or transformations if needed\n",
    "    # Prepare data for insertion\n",
    "    data_to_insert = (row['purchases'], row['date'], row['store_id'])\n",
    "    \n",
    "    # Execute the SQL command\n",
    "    try:\n",
    "        cursor.execute(insert_query, data_to_insert)\n",
    "        conn.commit()  # Commit changes for the current row only\n",
    "    except pymysql.Error as e:\n",
    "        print(f\"Error on row {index}: {e}\")\n",
    "        conn.rollback()  # Roll back the current row insertion only\n",
    "        continue  # Continue with the next row\n",
    "\n",
    "# Close the connection\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert visits-flujo to DB [Working]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/miniconda3/lib/python3.11/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/home/diego/miniconda3/lib/python3.11/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/home/diego/miniconda3/lib/python3.11/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/home/diego/miniconda3/lib/python3.11/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    }
   ],
   "source": [
    "tobalaba = pd.read_csv('tobalaba_flujo.csv')\n",
    "conce = pd.read_csv('conce_flujo.csv')\n",
    "quilin = pd.read_csv('quilin_flujo.csv')\n",
    "\n",
    "df_panoramico = pd.read_excel('/home/diego/Downloads/vivo_panomarico.xls', skiprows=4)\n",
    "df_plaza_los_rios = pd.read_excel('/home/diego/Downloads/plaza_los_rios.xls', skiprows=4)\n",
    "df_estado = pd.read_excel('/home/diego/Downloads/estado.xls', skiprows=4)\n",
    "df_apumanque = pd.read_excel('/home/diego/Downloads/apumanque.xls', skiprows=4)\n",
    "\n",
    "df_panoramico['FECHA'] = pd.to_datetime(df_panoramico['FECHA'], format='%Y-%m-%d')\n",
    "df_plaza_los_rios['FECHA'] = pd.to_datetime(df_plaza_los_rios['FECHA'], format='%Y-%m-%d')\n",
    "df_estado['FECHA'] = pd.to_datetime(df_estado['FECHA'], format='%Y-%m-%d')\n",
    "df_apumanque['FECHA'] = pd.to_datetime(df_apumanque['FECHA'], format='%Y-%m-%d')\n",
    "\n",
    "df_panoramico['store_id'] = 11\n",
    "df_plaza_los_rios['store_id'] = 9\n",
    "df_estado['store_id'] = 12\n",
    "df_apumanque['store_id'] = 10\n",
    "\n",
    "\n",
    "total_visits = pd.concat([df_panoramico, df_plaza_los_rios, df_estado, df_apumanque], ignore_index=True)\n",
    "\n",
    "# Connect to the database\n",
    "conn = pymysql.connect(host=HOST, user=ADMIN, password=PASS, database=DB)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# SQL Insert Statement\n",
    "insert_query = \"\"\"\n",
    "INSERT INTO visits (count, time, date, store_id)\n",
    "VALUES (%s, %s, %s, %s);\n",
    "\"\"\"\n",
    "\n",
    "# Prepare data for insertion\n",
    "data_to_insert = []\n",
    "for index, row in total_visits.iterrows():\n",
    "    date = pd.to_datetime(row['FECHA']).date()  # Ensuring date is in proper format\n",
    "    store_id = row['store_id']\n",
    "    for hour in range(24):\n",
    "        hour_key = f'{hour:02}'  # Format hour as two digits\n",
    "        count = row[hour_key]\n",
    "        if count > 0:\n",
    "            time = f'{hour_key}:00:00'  # Format time as HH:MM:SS\n",
    "            data_to_insert.append((count, time, date, store_id))\n",
    "\n",
    "# Insert data in chunks of 1000\n",
    "chunk_size = 1000\n",
    "for i in range(0, len(data_to_insert), chunk_size):\n",
    "    chunk = data_to_insert[i:i + chunk_size]\n",
    "    try:\n",
    "        cursor.executemany(insert_query, chunk)\n",
    "        conn.commit()\n",
    "    except pymysql.Error as e:\n",
    "        print(f\"Error inserting data: {e}\")\n",
    "        conn.rollback()  # Roll back the transaction\n",
    "\n",
    "# Close the connection\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales per category Load Sales Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "def load_sales_data():\n",
    "\t#### LODAD DATA ####\n",
    "\tdtype_spec = {\n",
    "\t\t'Tipo': 'int',\n",
    "\t\t'Numero': 'int',\n",
    "\t\t'Lin': 'int',\n",
    "\t\t'C.Bod': 'int',\n",
    "\t\t'Cant': 'int',\n",
    "\t\t'Venta': 'int',\n",
    "\t\t'Costo': 'int',\n",
    "\t\t'Margen': 'int',\n",
    "\t\t'Jerarquia': str,\n",
    "\t\t'Sub Jerarquia': str,\n",
    "\t\t'Local': str,\n",
    "\t\t'Color': str,\n",
    "\t\t'talla': str,\n",
    "\t\t'Marca': str,\n",
    "\t\t'temporada': str,\n",
    "\t\t'Rut': str,\n",
    "\t\t'Cliente': str\n",
    "\t}\n",
    "\t# Assuming 'df' is your DataFrame already loaded with the data\n",
    "\tsales_df = pd.read_csv('Ventas.csv', usecols=list(dtype_spec.keys()) + ['Fecha'], dtype=dtype_spec)\n",
    "\tsales_df['Fecha'] = pd.to_datetime(sales_df['Fecha'], format='%Y%m%d')\n",
    "\t# Define conditions\n",
    "\tconditions = [\n",
    "\t\tsales_df['Local'].str.strip().isin(['INTERNET']),  # Internet category\n",
    "\t\tsales_df['Local'].str.strip().isin(['BODEGA DOMINICA','BODEGA LDP', 'MAYORISTA', 'DARDIGNAC', 'BUENOS AIRES', 'SANTOS DUMONTT']),  # Mayoristas category\n",
    "\t\tsales_df['Local'].str.strip().isin(['CONCEPCION', 'VALDIVIA', 'MALL TOBALABA PTE.ALTO', 'APUMANQUE', 'PROVIDENCIA', 'ESTADO', 'MALL QUILIN'])  # No mayoristas category\n",
    "\t]\n",
    "\n",
    "\tchoices = [\n",
    "\t\t'Internet',  # Choice for Internet\n",
    "\t\t'Mayoristas',  # Choice for Mayoristas\n",
    "\t\t'No mayoristas'  # Choice for No mayoristas\n",
    "\t]\n",
    "\n",
    "\tsales_df['categories'] = np.select(conditions, choices, default='No mayoristas')  # Default can be adjusted if needed\n",
    "\n",
    "\tstore_dict = {\n",
    "\t\t'CONCEPCION': 1,\n",
    "\t\t'SANTOS DUMONTT': 2,\n",
    "\t\t'MALL TOBALABA PTE.ALTO': 3,\n",
    "\t\t'MALL QUILIN': 4,\n",
    "\t\t'INTERNET': 5,\n",
    "\t\t'DARDIGNAC': 6,\n",
    "\t\t'BUENOS AIRES': 7,\n",
    "\t\t'BODEGA LDP': 8,\n",
    "\t\t'VALDIVIA': 9,\n",
    "\t\t'APUMANQUE': 10,\n",
    "\t\t'PROVIDENCIA': 11,\n",
    "\t\t'ESTADO': 12,\n",
    "\t\t'MAYORISTA': 13,\n",
    "\t\t'BODEGA DOMINICA': 14\n",
    "\t}\n",
    "\n",
    "\tsales_df['store_id'] = sales_df['Local'].str.strip().map(store_dict).astype('Int64')\n",
    "\tsales_df['Fecha_Year_Month'] = sales_df['Fecha'].dt.to_period('M')\n",
    "\n",
    "#### LODAD DATA ####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert into Sales_agg [Working]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df = load_sales_data()\n",
    "\n",
    "category_sales = sales_df.groupby(['Local', 'Fecha_Year_Month']).agg(\n",
    "    total_sales=('Venta', 'sum'),                # Sum of the 'Venta' column for total sales\n",
    "    total_margin=('Margen', 'sum'),             # Sum of the 'Margen' column for total margins\n",
    "    count_items=('Numero', 'count'),            # Count of all occurrences of 'Numero'\n",
    "    unique_sales=('Numero', 'nunique'),         # Count of unique 'Numero' values\n",
    "    category=('categories', 'first')            # Get the first category value\n",
    ").reset_index()\n",
    "\n",
    "# Calculate 'Average Items per Transaction' by dividing the count of items by the count of unique sales\n",
    "category_sales['Average Items per Transaction'] = category_sales['count_items'] / category_sales['unique_sales']\n",
    "\n",
    "# Optionally, round the 'Average Items per Transaction' to a sensible number of decimal places, e.g., 2\n",
    "category_sales['Average Items per Transaction'] = category_sales['Average Items per Transaction'].round(2)\n",
    "\n",
    "# Sort the resulting DataFrame by 'total_sales' if needed\n",
    "category_sales_sorted = category_sales.sort_values(by='total_sales', ascending=False)\n",
    "\n",
    "# Display the top 100 entries in the DataFrame\n",
    "category_sales_sorted.head(n=1000)\n",
    "\n",
    "\n",
    "store_dict = {\n",
    "    'CONCEPCION': 1,\n",
    "    'SANTOS DUMONTT': 2,\n",
    "    'MALL TOBALABA PTE.ALTO': 3,\n",
    "    'MALL QUILIN': 4,\n",
    "    'INTERNET': 5,\n",
    "    'DARDIGNAC': 6,\n",
    "    'BUENOS AIRES': 7,\n",
    "    'BODEGA LDP': 8,\n",
    "    'VALDIVIA': 9,\n",
    "    'APUMANQUE': 10,\n",
    "    'PROVIDENCIA': 11,\n",
    "    'ESTADO': 12,\n",
    "    'MAYORISTA': 13,\n",
    "    'BODEGA DOMINICA': 14\n",
    "}\n",
    "\n",
    "conn = pymysql.connect(host=HOST, user=ADMIN, password=PASS, database=DB)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# SQL Insert Statement\n",
    "insert_query = \"\"\"\n",
    "INSERT INTO sales_agg (date, store_id, total_sales, total_margin, count_items, unique_sales) VALUES (%s, %s, %s, %s, %s, %s);\n",
    "\"\"\"\n",
    "\n",
    "# Iterate over DataFrame rows\n",
    "for index, row in category_sales_sorted.iterrows():\n",
    "    # Prepare data for insertion\n",
    "    if row['store_id'] is None:\n",
    "        print(f\"Store ID not found for '{row['Local']}'\")\n",
    "        continue\n",
    "\n",
    "    # Assuming store_id is correctly assigned before this line as your example did not clarify where it comes from\n",
    "    store_id = row['store_id']\n",
    "\n",
    "    data_to_insert = (f\"{row['Fecha_Year_Month']}-01\", store_id, row['total_sales'], row['total_margin'], row['count_items'], row['unique_sales'])\n",
    "    \n",
    "    # Execute the SQL command\n",
    "    try:\n",
    "        cursor.execute(insert_query, data_to_insert)\n",
    "        conn.commit()  # Commit changes for the current row only\n",
    "    except pymysql.Error as e:\n",
    "        print(f\"Error on row {index}: {e}\")\n",
    "        conn.rollback()  # Roll back the current row insertion only\n",
    "        continue  # Continue with the next row\n",
    "\n",
    "\n",
    "# Close the connection\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert into sales Agg per Day [Working]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df = load_sales_data()\n",
    "\n",
    "sales_agg_per_day = sales_df.groupby(['Local', 'Fecha']).agg(\n",
    "    total_sales=('Venta', 'sum'),                # Sum of the 'Venta' column for total sales\n",
    "    total_margin=('Margen', 'sum'),             # Sum of the 'Margen' column for total margins\n",
    "    count_items=('Numero', 'count'),            # Count of all occurrences of 'Numero'\n",
    "    unique_sales=('Numero', 'nunique'),         # Count of unique 'Numero' values\n",
    "    category=('categories', 'first'),          # Get the first category value\n",
    "    store_id=('store_id', 'first'),          # Get the first category value\n",
    ").reset_index()\n",
    "\n",
    "conn = pymysql.connect(host=HOST, user=ADMIN, password=PASS, database=DB)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# SQL Insert Statement\n",
    "insert_query = \"\"\"\n",
    "INSERT INTO sales (date, store_id, total_sales, total_margin, count_items, unique_sales) VALUES (%s, %s, %s, %s, %s, %s);\n",
    "\"\"\"\n",
    "\n",
    "# Prepare data for insertion\n",
    "data_to_insert = []\n",
    "for index, row in sales_agg_per_day.iterrows():\n",
    "    if row['store_id'] is None:\n",
    "        print(f\"Store ID not found for '{row['Local']}'\")\n",
    "        continue\n",
    "\n",
    "    # Assuming store_id is correctly assigned before this line as your example did not clarify where it comes from\n",
    "    store_id = row['store_id']\n",
    "    data_to_insert.append((row['Fecha'], store_id, row['total_sales'], row['total_margin'], row['count_items'], row['unique_sales']))\n",
    "\n",
    "# Insert data in chunks\n",
    "chunk_size = 1000  # Define the size of each chunk\n",
    "for i in range(0, len(data_to_insert), chunk_size):\n",
    "    chunk = data_to_insert[i:i + chunk_size]\n",
    "    try:\n",
    "        cursor.executemany(insert_query, chunk)\n",
    "        conn.commit()\n",
    "    except pymysql.Error as e:\n",
    "        print(f\"Error inserting data: {e}\")\n",
    "        conn.rollback()  # Roll back the transaction if an error occurs\n",
    "\n",
    "# Close the connection\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
