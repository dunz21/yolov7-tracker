{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select 4 best images from all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import shutil\n",
    "\n",
    "BASE_FOLDER_NAME = 'results'\n",
    "FOLDER_PATH_IMGS = '/home/diego/Documents/yolov7-tracker/imgs_conce/'\n",
    "K_FOLD = 4\n",
    "DEST_FOLDER_PATH_IMGS = f'/home/diego/Documents/yolov7-tracker/imgs_conce_top{K_FOLD}/'\n",
    "MODEL_RESULT = os.path.join(BASE_FOLDER_NAME, 'total_model_img_selction_conce_bbox.csv')\n",
    "THRESHOLD = 0.9\n",
    "\n",
    "df = pd.read_csv(MODEL_RESULT)\n",
    "\n",
    "# Correctly format 'model_label_conf' with 2 decimal places\n",
    "df['model_label_conf'] = df['model_label_conf'].round(2)\n",
    "\n",
    "\n",
    "df['new_k_fold'] = None\n",
    "df['selected_image'] = False\n",
    "\n",
    "# Saco los IDs correspondientes a los BAD\n",
    "bad_ids = df[df['label_direction'] == 'BAD']['id'].unique()\n",
    "filtered_df = df[~df['id'].isin(bad_ids)]\n",
    "\n",
    "# Order by id and frame_number\n",
    "filtered_df.sort_values(by=['id', 'frame_number'], inplace=True)\n",
    "\n",
    "# Ensure the destination folder exists\n",
    "if not os.path.exists(DEST_FOLDER_PATH_IMGS):\n",
    "    os.makedirs(DEST_FOLDER_PATH_IMGS)\n",
    "\n",
    "# Function to move selected images\n",
    "def copy_images(row):\n",
    "    source_path = os.path.join(FOLDER_PATH_IMGS, row['img_name'].split('_')[1], row['img_name'])\n",
    "    dest_path = source_path.replace(FOLDER_PATH_IMGS, DEST_FOLDER_PATH_IMGS)\n",
    "    os.makedirs(os.path.dirname(dest_path), exist_ok=True)\n",
    "    shutil.copy(source_path, dest_path)  # Use shutil.copy instead of shutil.move\n",
    "\n",
    "# Iterate over each unique id\n",
    "for id_value in filtered_df['id'].unique():\n",
    "    id_df = filtered_df[filtered_df['id'] == id_value]\n",
    "    \n",
    "    # Adjust threshold if necessary\n",
    "    while True:\n",
    "        filtered_id_df = id_df[(id_df['model_label_conf'] > THRESHOLD) & (id_df['model_label_img'] == 2)].copy()\n",
    "        \n",
    "        if len(filtered_id_df) >= K_FOLD or THRESHOLD <= 0:\n",
    "            break\n",
    "        THRESHOLD -= 0.05\n",
    "    \n",
    "    # If we have enough images, perform K-Fold and select one image per fold\n",
    "    if len(filtered_id_df) >= K_FOLD:\n",
    "        kf = KFold(n_splits=K_FOLD)\n",
    "        \n",
    "        for fold_number, (_, test_index) in enumerate(kf.split(filtered_id_df), start=1):\n",
    "\n",
    "            # selected_indices = np.random.choice(test_index, 1, replace=False)\n",
    "\n",
    "            fold_df = filtered_id_df.iloc[test_index]\n",
    "            selected_row = fold_df.sample(n=1)\n",
    "            selected_index = selected_row.index\n",
    "            \n",
    "            # Update the DataFrame with fold and selection information\n",
    "            df.loc[selected_index, 'new_k_fold'] = fold_number\n",
    "            df.loc[selected_index, 'selected_image'] = True\n",
    "            \n",
    "            # Move the selected image\n",
    "            selected_row.apply(copy_images, axis=1)\n",
    "\n",
    "# Optionally, save the updated DataFrame to a CSV file\n",
    "# df.to_csv('logs/updated_model_results_with_kfold.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Re ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def re_ranking(probFea, galFea, k1, k2, lambda_value, local_distmat = None, only_local = False):\n",
    "    # if feature vector is numpy, you should use 'torch.tensor' transform it to tensor\n",
    "    query_num = probFea.size(0)\n",
    "    all_num = query_num + galFea.size(0)\n",
    "    if only_local:\n",
    "        original_dist = local_distmat\n",
    "    else:\n",
    "        feat = torch.cat([probFea,galFea])\n",
    "        # print('using GPU to compute original distance')\n",
    "        distmat = torch.pow(feat,2).sum(dim=1, keepdim=True).expand(all_num,all_num) + \\\n",
    "                      torch.pow(feat, 2).sum(dim=1, keepdim=True).expand(all_num, all_num).t()\n",
    "        distmat.addmm_(1,-2,feat,feat.t())\n",
    "        original_dist = distmat.numpy()\n",
    "        del feat\n",
    "        if not local_distmat is None:\n",
    "            original_dist = original_dist + local_distmat\n",
    "    gallery_num = original_dist.shape[0]\n",
    "    original_dist = np.transpose(original_dist / np.max(original_dist, axis=0))\n",
    "    V = np.zeros_like(original_dist).astype(np.float16)\n",
    "    initial_rank = np.argsort(original_dist).astype(np.int32)\n",
    "\n",
    "#     print('starting re_ranking')\n",
    "    for i in range(all_num):\n",
    "        # k-reciprocal neighbors\n",
    "        forward_k_neigh_index = initial_rank[i, :k1 + 1]\n",
    "        backward_k_neigh_index = initial_rank[forward_k_neigh_index, :k1 + 1]\n",
    "        fi = np.where(backward_k_neigh_index == i)[0]\n",
    "        k_reciprocal_index = forward_k_neigh_index[fi]\n",
    "        k_reciprocal_expansion_index = k_reciprocal_index\n",
    "        for j in range(len(k_reciprocal_index)):\n",
    "            candidate = k_reciprocal_index[j]\n",
    "            candidate_forward_k_neigh_index = initial_rank[candidate, :int(np.around(k1 / 2)) + 1]\n",
    "            candidate_backward_k_neigh_index = initial_rank[candidate_forward_k_neigh_index,\n",
    "                                               :int(np.around(k1 / 2)) + 1]\n",
    "            fi_candidate = np.where(candidate_backward_k_neigh_index == candidate)[0]\n",
    "            candidate_k_reciprocal_index = candidate_forward_k_neigh_index[fi_candidate]\n",
    "            if len(np.intersect1d(candidate_k_reciprocal_index, k_reciprocal_index)) > 2 / 3 * len(\n",
    "                    candidate_k_reciprocal_index):\n",
    "                k_reciprocal_expansion_index = np.append(k_reciprocal_expansion_index, candidate_k_reciprocal_index)\n",
    "\n",
    "        k_reciprocal_expansion_index = np.unique(k_reciprocal_expansion_index)\n",
    "        weight = np.exp(-original_dist[i, k_reciprocal_expansion_index])\n",
    "        V[i, k_reciprocal_expansion_index] = weight / np.sum(weight)\n",
    "    original_dist = original_dist[:query_num, ]\n",
    "    if k2 != 1:\n",
    "        V_qe = np.zeros_like(V, dtype=np.float16)\n",
    "        for i in range(all_num):\n",
    "            V_qe[i, :] = np.mean(V[initial_rank[i, :k2], :], axis=0)\n",
    "        V = V_qe\n",
    "        del V_qe\n",
    "    del initial_rank\n",
    "    invIndex = []\n",
    "    for i in range(gallery_num):\n",
    "        invIndex.append(np.where(V[:, i] != 0)[0])\n",
    "\n",
    "    jaccard_dist = np.zeros_like(original_dist, dtype=np.float16)\n",
    "\n",
    "    for i in range(query_num):\n",
    "        temp_min = np.zeros(shape=[1, gallery_num], dtype=np.float16)\n",
    "        indNonZero = np.where(V[i, :] != 0)[0]\n",
    "        indImages = [invIndex[ind] for ind in indNonZero]\n",
    "        for j in range(len(indNonZero)):\n",
    "            temp_min[0, indImages[j]] = temp_min[0, indImages[j]] + np.minimum(V[i, indNonZero[j]],\n",
    "                                                                               V[indImages[j], indNonZero[j]])\n",
    "        jaccard_dist[i] = 1 - temp_min / (2 - temp_min)\n",
    "\n",
    "    final_dist = jaccard_dist * (1 - lambda_value) + original_dist * lambda_value\n",
    "    del original_dist\n",
    "    del V\n",
    "    del jaccard_dist\n",
    "    final_dist = final_dist[:query_num, query_num:]\n",
    "    return final_dist\n",
    "\n",
    "def eval_simplified_with_matches(distmat, q_pids, g_pids):\n",
    "    indices = np.argsort(distmat, axis=1)  # Sorted indices of gallery samples for each query\n",
    "    matchs = np.hstack((q_pids[:, np.newaxis], g_pids[indices]))\n",
    "    return matchs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mejorar esto y hacerlo solo con SOLIDER CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct OUTs: 114 Total OUTs: 564 Diff: [   14    16   134   135   279   280   298   372   466   665   759   828\n",
      "  1060  1082  1198  1302  1324  1333  1374  1418  1436  1476  1488  1561\n",
      "  1578  1679  1737  1761  1793  1854  1868  1870  1965  1993  2013  2032\n",
      "  2054  2111  2129  2204  2265  2344  2350  2353  2354  2465  2550  2553\n",
      "  2663  2716  2734  2781  2820  2857  2891  2917  2989  3136  3306  3307\n",
      "  3311  3357  3371  3419  3436  3438  3440  3474  3480  3483  3486  3503\n",
      "  3504  3619  3620  3628  3777  3793  3817  3852  3921  3962  3980  3993\n",
      "  3994  3995  4022  4023  4027  4078  4092  4120  4134  4200  4246  4267\n",
      "  4274  4275  4286  4292  4333  4345  4346  4358  4370  4427  4428  4467\n",
      "  4471  4478  4481  4494  4503  4515  4541  4548  4598  4617  4632  4641\n",
      "  4692  4708  4710  4711  4748  4763  4785  4820  4822  4830  4832  4841\n",
      "  4843  4845  4879  4880  4899  4907  4923  4957  4960  4961  4962  4972\n",
      "  4973  4999  5015  5022  5107  5144  5150  5156  5158  5159  5164  5195\n",
      "  5205  5207  5214  5226  5261  5268  5271  5290  5299  5301  5326  5327\n",
      "  5361  5362  5366  5390  5391  5392  5406  5440  5444  5452  5455  5471\n",
      "  5509  5521  5526  5556  5578  5597  5600  5622  5623  5624  5641  5650\n",
      "  5671  5692  5734  5736  5766  5850  5866  5875  5897  5900  5916  5917\n",
      "  5919  5920  5965  5970  5971  5996  6004  6010  6022  6035  6057  6079\n",
      "  6101  6113  6114  6115  6146  6162  6169  6170  6171  6210  6216  6237\n",
      "  6363  6374  6389  6410  6413  6451  6467  6468  6490  6521  6564  6571\n",
      "  6579  6580  6581  6592  6603  6610  6611  6614  6653  6654  6657  6685\n",
      "  6709  6710  6727  6732  6934  6935  6956  6957  6976  7031  7067  7072\n",
      "  7086  7111  7137  7197  7208  7213  7236  7237  7259  7262  7272  7274\n",
      "  7310  7374  7383  7394  7413  7429  7433  7434  7473  7474  7520  7525\n",
      "  7564  7568  7594  7595  7613  7614  7629  7640  7650  7693  7694  7710\n",
      "  7741  7762  7780  7781  7801  7807  7827  7830  7866  7950  7953  7955\n",
      "  7958  7961  7966  8001  8002  8013  8086  8090  8106  8108  8194  8196\n",
      "  8197  8198  8223  8235  8245  8250  8322  8323  8334  8382  8386  8390\n",
      "  8393  8394  8411  8413  8446  8503  8572  8583  8647  8648  8674  8793\n",
      "  8804  8805  8809  8814  8822  8823  8839  8891  8893  8895  8947  8973\n",
      "  8976  9032  9066  9084  9088  9094  9122  9123  9139  9152  9154  9161\n",
      "  9168  9173  9176  9177  9181  9187  9188  9212  9213  9287  9288  9341\n",
      "  9363  9365  9391  9394  9402  9414  9463  9464  9507  9522  9533  9534\n",
      "  9574  9585  9587  9610  9648  9650  9651  9664  9666  9672  9673  9676\n",
      "  9682  9747  9749  9750  9791  9794  9807  9846  9853  9855  9865  9867\n",
      "  9885  9886  9909  9911  9975  9990  9995  9997 10013 10082 10108 10113\n",
      " 10114 10117 10152 10155 10171 10176 10215 10267 10272 10273 10331 10343\n",
      " 10345 10368 10374 10381 10395 10396 10412 10434 10445]\n",
      "Correct INs: 114 Total INs: 583 Diff: [   78   142   143   236   398   441   484   543   550   570   697   699\n",
      "   816   817   843   846   911   954  1045  1072  1126  1227  1231  1264\n",
      "  1366  1391  1404  1414  1420  1572  1630  1631  1692  1698  1724  1836\n",
      "  1897  1942  1943  1986  2039  2081  2139  2154  2173  2286  2331  2346\n",
      "  2457  2489  2542  2547  2566  2585  2656  2686  2704  2723  2724  2727\n",
      "  2780  2792  2819  2825  2835  2847  2870  3024  3059  3063  3065  3075\n",
      "  3079  3083  3178  3280  3333  3352  3411  3444  3467  3469  3544  3593\n",
      "  3668  3716  3762  3780  3826  3839  3841  3878  3896  3922  3942  3943\n",
      "  3948  3949  4020  4021  4050  4051  4055  4077  4149  4177  4178  4186\n",
      "  4187  4209  4210  4211  4215  4217  4232  4235  4255  4264  4285  4295\n",
      "  4297  4307  4325  4328  4331  4342  4350  4383  4384  4408  4437  4439\n",
      "  4446  4450  4549  4550  4553  4568  4609  4644  4648  4649  4656  4657\n",
      "  4681  4684  4756  4773  4797  4806  4808  4809  4818  4851  4898  4903\n",
      "  4906  4982  4984  4985  4989  5018  5025  5035  5060  5064  5106  5110\n",
      "  5114  5116  5117  5131  5147  5176  5189  5193  5197  5217  5221  5239\n",
      "  5267  5287  5318  5345  5346  5348  5355  5357  5360  5394  5396  5397\n",
      "  5407  5412  5413  5426  5429  5430  5433  5434  5442  5457  5477  5490\n",
      "  5504  5510  5513  5533  5540  5567  5592  5594  5609  5638  5744  5801\n",
      "  5808  5813  5824  5846  5848  5870  5899  5932  5942  5957  5999  6005\n",
      "  6017  6023  6031  6033  6037  6121  6140  6154  6157  6185  6186  6195\n",
      "  6205  6226  6259  6317  6328  6329  6348  6392  6402  6404  6426  6436\n",
      "  6452  6457  6495  6531  6547  6560  6569  6575  6576  6583  6584  6691\n",
      "  6707  6708  6721  6752  6753  6763  6764  6790  6858  6862  6863  6921\n",
      "  6924  6952  6971  6979  6993  6996  7040  7081  7082  7152  7153  7179\n",
      "  7180  7181  7193  7199  7225  7277  7319  7347  7348  7361  7409  7417\n",
      "  7418  7430  7431  7441  7461  7489  7495  7567  7584  7604  7606  7620\n",
      "  7625  7643  7656  7667  7691  7721  7722  7730  7773  7774  7793  7808\n",
      "  7881  7885  7906  7908  7911  7917  7931  7947  7968  7988  7991  8058\n",
      "  8076  8118  8122  8125  8127  8128  8133  8145  8146  8147  8148  8150\n",
      "  8153  8154  8156  8239  8263  8324  8355  8356  8362  8401  8408  8409\n",
      "  8432  8455  8460  8501  8515  8535  8547  8584  8587  8588  8592  8595\n",
      "  8597  8616  8679  8681  8706  8708  8718  8730  8739  8764  8774  8788\n",
      "  8837  8858  8872  8902  8905  8914  8938  8968  8971  9020  9052  9059\n",
      "  9079  9087  9096  9106  9111  9158  9160  9162  9192  9256  9267  9273\n",
      "  9336  9337  9338  9426  9461  9462  9467  9469  9505  9512  9529  9530\n",
      "  9549  9621  9623  9642  9680  9685  9686  9689  9696  9697  9704  9709\n",
      "  9738  9741  9768  9769  9806  9810  9824  9840  9843  9875  9876  9905\n",
      "  9919  9935  9941  9943  9945  9949  9959  9999 10036 10039 10050 10066\n",
      " 10106 10107 10157 10183 10192 10225 10233 10242 10244 10246 10249 10263\n",
      " 10292 10317 10321 10338 10371 10378 10401 10428 10448]\n",
      "1488\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "features = pd.read_csv('../output/conce_solider_in-out_DB.csv')\n",
    "for col in features.columns[3:]:  \n",
    "\t\tfeatures[col] = features[col].astype(float)\n",
    "\n",
    "correct_labels = pd.read_csv('/home/diego/Desktop/MatchSimple.csv')\n",
    "ids_correct_outs = correct_labels['OUT'].values\n",
    "ids_correct_ins = correct_labels['IN'].values\n",
    "\n",
    "print(f\"Correct OUTs: {len(ids_correct_outs)} Total OUTs: {len(features[features['Direction'] == 'Out']['ID'].unique())} Diff: {len(features[(features['Direction'] == 'Out') & (~features['ID'].isin(ids_correct_outs)) ]['ID'].unique())}\")\n",
    "print(f\"Correct INs: {len(ids_correct_ins)} Total INs: {len(features[features['Direction'] == 'In']['ID'].unique())} Diff: {len(features[(features['Direction'] == 'In') & (~features['ID'].isin(ids_correct_ins)) ]['ID'].unique())}\")\n",
    "\n",
    "id_out_list = features[(features['Direction'] == 'Out') & (~features['ID'].isin(ids_correct_outs)) ]['ID'].unique()\n",
    "id_in_list = features[(features['Direction'] == 'In') & (~features['ID'].isin(ids_correct_ins)) ]['ID'].unique()\n",
    "\n",
    "query = []\n",
    "gallery = []\n",
    "results_list = []\n",
    "rank = 5\n",
    "# Iterate over each id_out to construct query and gallery\n",
    "for index,id_out in enumerate(id_out_list):\n",
    "\t\tif id_out < id_in_list[0]:\n",
    "\t\t\tcontinue\n",
    "\t\t\t\n",
    "\t\tif id_out == 1488:\n",
    "\t\t\tprint(id_out)\n",
    "\t\tquery_features = features[features['ID'] == id_out].iloc[:, 3:].to_numpy()\n",
    "\t\tquery = torch.tensor(query_features, dtype=torch.float32)\n",
    "\t\tq_pids = features[features['ID'] == id_out]['ID'].values\n",
    "\n",
    "\t\tgallery_features = features[(features['ID'] < id_out) & (features['Direction'] == 'In')].iloc[:, 3:].to_numpy()  # Adjust based on your logic\n",
    "\t\tgallery = torch.tensor(gallery_features, dtype=torch.float32)\n",
    "\t\tg_pids = features[(features['ID'] < id_out) & (features['Direction'] == 'In')]['ID'].values\n",
    "\n",
    "\t\t# Assuming id_in < id_out, adjust your logic as needed\n",
    "\t\tq_ids = [id_in for id_in in id_in_list if id_in < id_out]\n",
    "\t\t# Normalize features\n",
    "\t\tquery = query / query.norm(dim=1, keepdim=True)\n",
    "\t\tgallery = gallery / gallery.norm(dim=1, keepdim=True)\n",
    "\n",
    "\t\tdistmat = re_ranking(query, gallery, 4, 2, 0.3)\n",
    "\t\tmatching_gallery_ids = eval_simplified_with_matches(distmat, q_pids, g_pids)\n",
    "\t\tfor row in matching_gallery_ids[:, :rank+1]:  # Assuming you're interested in the first 6 columns\n",
    "\t\t\t\tresults_list.append(row.tolist())\n",
    "\n",
    "num_ranks = matching_gallery_ids.shape[1] if matching_gallery_ids.size > 0 else 0\n",
    "column_names = ['query'] + [f'rank{i}' for i in range(1, num_ranks)]\n",
    "# Create DataFrame\n",
    "re_ranking_results = pd.DataFrame(results_list, columns=column_names[:rank+1])  # Adjust column slicing as necessary\n",
    "# Save to CSV\n",
    "re_ranking_results.to_csv('../output/re_ranking.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re ranking HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "BASE_FOLDER = '/home/diego/Documents/yolov7-tracker/imgs_conce_top4/'\n",
    "FRAME_RATE = 15\n",
    "\n",
    "def seconds_to_time(seconds):\n",
    "    # Create a timedelta object\n",
    "    td = datetime.timedelta(seconds=seconds)\n",
    "    # Add the timedelta to a minimal datetime object\n",
    "    time = (datetime.datetime.min + td).time()\n",
    "    # Convert to a string format\n",
    "    return time.strftime(\"%H:%M:%S\")\n",
    "\n",
    "def _image_formatter(folder_id, index_img, query_frame_number):\n",
    "    folder_path = os.path.join(BASE_FOLDER, str(folder_id))\n",
    "\n",
    "    try:\n",
    "        images_list = sorted(os.listdir(folder_path))  # Ensure consistent order\n",
    "        if index_img <= len(images_list):\n",
    "            img_file = images_list[index_img - 1]  # -1 because list index starts at 0\n",
    "            img_frame_number = int(img_file.split('_')[2])\n",
    "            img_path = os.path.join(folder_path, img_file)\n",
    "            with open(img_path, \"rb\") as f:\n",
    "                encoded_string = base64.b64encode(f.read()).decode()\n",
    "                time = seconds_to_time(max(0,(query_frame_number - img_frame_number)) // FRAME_RATE)\n",
    "                return f'<div><img width=\"125\" src=\"data:image/png;base64,{encoded_string}\"><div>ID: {img_file.split(\"_\")[1]} - {time} </div></div>'\n",
    "        else:\n",
    "            return \"Image index out of range\"\n",
    "    except OSError as e:\n",
    "        # Including more specific error information\n",
    "        return f\"OSError: {e}, File: {img_path}\"\n",
    "    except FileNotFoundError:\n",
    "        return \"Folder or image not found\"\n",
    "    \n",
    "re_ranking = pd.read_csv('../output/re_ranking.csv')\n",
    "\n",
    "# Create DataFrame after calculating 'index_img'\n",
    "df = pd.DataFrame({\n",
    "    'Query': re_ranking['query'],\n",
    "    'Rank1': re_ranking['rank1'],\n",
    "    'Rank2': re_ranking['rank2'],\n",
    "    'Rank3': re_ranking['rank3'],\n",
    "    'Rank4': re_ranking['rank4'],\n",
    "    'Rank5': re_ranking['rank5']\n",
    "})\n",
    "df['IndexImg'] = re_ranking.groupby('query').cumcount() + 1\n",
    "\n",
    "\n",
    "\n",
    "def get_frame_number(folder_id):\n",
    "\tquery_image_name =  os.path.join(BASE_FOLDER, str(folder_id))\n",
    "\tquery_images_list = sorted(os.listdir(query_image_name))  # Ensure consistent order\n",
    "\tquery_image = query_images_list[0]\n",
    "\tquery_frame_number = int(query_image.split('_')[2])\n",
    "\treturn query_frame_number\n",
    "        \n",
    "\n",
    "df['frame_number_query'] = df['Query'].apply(get_frame_number)\n",
    "\n",
    "for rank in ['Query', 'Rank1', 'Rank2', 'Rank3', 'Rank4', 'Rank5']:\n",
    "\tdf[rank] = df.apply(lambda x: _image_formatter(x[rank], x['IndexImg'],x['frame_number_query']), axis=1)\n",
    "\n",
    "html_df2 = df[['Query','Rank1','Rank2','Rank3','Rank4','Rank5']].to_html(escape=False, index=False)\n",
    "\n",
    "with open('../output/re_rank.html', 'w') as file:\n",
    "        file.write(html_df2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
