{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "BASE_IMAGES_PATH = '/home/diego/Documents/yolov7-tracker/imgs_conce'\n",
    "BASE_FOLDER_NAME = 'results'\n",
    "FILE_NAME = 'conce_bbox.csv'\n",
    "CSV_FILE_PATH = os.path.join(BASE_FOLDER_NAME,FILE_NAME)\n",
    "TMP_120 = os.path.join(BASE_FOLDER_NAME,'data_prep_conce_bbox.csv')\n",
    "TMP_130 = os.path.join(BASE_FOLDER_NAME,f\"130_{FILE_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add images to CSV BBOX [110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "def find_image_name(row, image_dict):\n",
    "    \"\"\"\n",
    "    Construct the image name based on row's id and frame_number,\n",
    "    then check if it exists in the image_dict.\n",
    "    \"\"\"\n",
    "    id_frame_pattern = f\"img_{int(row['id'])}_{int(row['frame_number'])}\"\n",
    "    matched_images = [img for img in image_dict.get(int(row['id']), []) if id_frame_pattern in img]\n",
    "    return matched_images[0] if matched_images else None\n",
    "\n",
    "def append_image_names(csv_path, base_path):\n",
    "    # Load the CSV into a DataFrame\n",
    "    df = pd.read_csv(csv_path, dtype={'id': 'int64','frame_number': 'int64'})\n",
    "\n",
    "    # Dictionary to hold image names for each id\n",
    "    image_dict = {}\n",
    "\n",
    "    # List directories in the base path and filter by those matching the ids in the DataFrame\n",
    "    for dir_name in os.listdir(base_path):\n",
    "        dir_path = os.path.join(base_path, dir_name)\n",
    "        if os.path.isdir(dir_path) and dir_name.isdigit():\n",
    "            id = int(dir_name)\n",
    "            # List all images for the current id\n",
    "            image_dict[id] = [os.path.basename(x) for x in glob.glob(os.path.join(dir_path, \"*.png\"))]\n",
    "\n",
    "    # Apply the function to find the matching image name for each row\n",
    "    df['img_name'] = df.apply(lambda row: find_image_name(row, image_dict), axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "updated_df = append_image_names(CSV_FILE_PATH, BASE_IMAGES_PATH)\n",
    "updated_df.to_csv(CSV_FILE_PATH, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add kfold to images and add label_img, label_direction column [110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-importing necessary libraries and redefining the function with corrections\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import os\n",
    "# Re-defining the set_folds function\n",
    "def set_folds(csv_path, k_folds, n_images):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Ensure 'img_name' column exists\n",
    "    if 'img_name' not in df.columns:\n",
    "        raise ValueError(\"img_name column doesn't exist in the dataset.\")\n",
    "\n",
    "    # Initialize k_fold column in original df\n",
    "    df['k_fold'] = np.nan\n",
    "    df['label_img'] = np.nan\n",
    "    df['label_direction'] = np.nan\n",
    "\n",
    "    # Filter rows where 'img_name' is not empty\n",
    "    df_filtered = df[df['img_name'] != ''].copy()\n",
    "\n",
    "    # Sort by 'id' and 'frame_number'\n",
    "    df_filtered.sort_values(by=['id', 'frame_number'], inplace=True)\n",
    "\n",
    "    # Process each ID separately in filtered df\n",
    "    for id_value in df_filtered['id'].unique():\n",
    "        subset = df_filtered[(df_filtered['id'] == id_value) & (df_filtered['img_name'].notna())]\n",
    "\n",
    "        # Apply KFold or assign all to the same fold if condition is met\n",
    "        if len(subset) < k_folds * n_images:\n",
    "            df.loc[subset.index, 'k_fold'] = 0  # Assign all to fold 0 if condition is met\n",
    "        else:\n",
    "            # Apply KFold\n",
    "            kf = KFold(n_splits=k_folds)\n",
    "            for fold, (_, test_index) in enumerate(kf.split(subset)):\n",
    "                # Select n_images per fold if specified\n",
    "                #selected_indices = test_index[:n_images] if n_images < len(test_index) else test_index Selecciona los primeros n_images\n",
    "                selected_indices = np.random.choice(test_index, min(n_images, len(test_index)), replace=False)\n",
    "                df.loc[subset.iloc[selected_indices].index, 'k_fold'] = fold\n",
    "                df.loc[subset.iloc[selected_indices].index, 'label_img'] = 0\n",
    "    return df\n",
    "\n",
    "\n",
    "df_with_folds = set_folds(CSV_FILE_PATH, k_folds=5, n_images=3)\n",
    "df_with_folds.to_csv(CSV_FILE_PATH, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data process IN vs OUT Feature Engineering [FINAL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_csv(CSV_FILE_PATH)\n",
    "\n",
    "\n",
    "## TEMPORAL ###\n",
    "label_index = df.columns.get_loc('label_direction')\n",
    "df = df.iloc[:, :label_index + 1]\n",
    "## TEMPORAL ###\n",
    "\n",
    "# Ensure the DataFrame is sorted by 'id' and 'frame_number' for correct diff calculations\n",
    "df.sort_values(by=['id', 'frame_number'], inplace=True)\n",
    "\n",
    "# Calculate Movement Features (Δx and Δy)\n",
    "df['delta_x'] = df.groupby('id')['centroid_x'].diff().fillna(0)\n",
    "df['delta_y'] = df.groupby('id')['centroid_y'].diff().fillna(0)\n",
    "\n",
    "# Calculate Initial and Final Position Features without using frame_number\n",
    "df['initial_x'] = df.groupby('id')['centroid_x'].transform('first')\n",
    "df['initial_y'] = df.groupby('id')['centroid_y'].transform('first')\n",
    "df['final_x'] = df.groupby('id')['centroid_x'].transform('last')\n",
    "df['final_y'] = df.groupby('id')['centroid_y'].transform('last')\n",
    "\n",
    "# Calculate total distance traveled without frame_number\n",
    "df['total_distance'] = np.sqrt((df['final_x'] - df['initial_x'])**2 + (df['final_y'] - df['initial_y'])**2)\n",
    "\n",
    "# Assuming that the ordering of frames is implicitly represented by their position in the DataFrame,\n",
    "# you can calculate movement features based on the assumption that earlier rows are earlier in time\n",
    "# However, since we're not using frame_number for temporal division, we'll skip avg_move_per_frame_x and avg_move_per_frame_y\n",
    "\n",
    "# Instead, focus on proportional change without direct temporal context\n",
    "# Calculate the difference in positions as a proxy for movement direction and magnitude\n",
    "df['delta_x'] = df['final_x'] - df['initial_x']\n",
    "df['delta_y'] = df['final_y'] - df['initial_y']\n",
    "\n",
    "# Optionally, calculate normalized movement direction vectors if needed\n",
    "df['direction_x'] = df['delta_x'] / df['total_distance']\n",
    "df['direction_y'] = df['delta_y'] / df['total_distance']\n",
    "df['direction_x'] = df['direction_x'].fillna(0)  # Handle division by zero if total_distance is 0\n",
    "df['direction_y'] = df['direction_y'].fillna(0)\n",
    "\n",
    "# Calculate Aggregated Features for each ID\n",
    "aggregations = {\n",
    "    'delta_x': ['mean','max', 'min','std'],\n",
    "    'delta_y': ['mean','max', 'min','std'],\n",
    "}\n",
    "aggregated_features = df.groupby('id').agg(aggregations).reset_index()\n",
    "\n",
    "# Correct the naming of the aggregated columns\n",
    "aggregated_features.columns = ['id'] + [f'{var}_{stat}' for var, stats in aggregations.items() for stat in stats]\n",
    "\n",
    "# Correctly merge aggregated features back to the original dataframe\n",
    "df = pd.merge(df, aggregated_features, on='id', how='left')\n",
    "\n",
    "# Calculate Sequence Features (net movement direction)\n",
    "df['net_movement_x'] = df.groupby('id')['delta_x'].transform('sum')\n",
    "df['net_movement_y'] = df.groupby('id')['delta_y'].transform('sum')\n",
    "\n",
    "df.to_csv(TMP_120, index=False)\n",
    "\n",
    "print(\"Updated CSV saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Process IN_OUT vs BAD Feature Engineering [130]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_csv(CSV_FILE_PATH)\n",
    "\n",
    "\n",
    "## TEMPORAL ###\n",
    "label_index = df.columns.get_loc('label_direction')\n",
    "df = df.iloc[:, :label_index + 1]\n",
    "## TEMPORAL ###\n",
    "\n",
    "# Ensure the DataFrame is sorted by 'id' and 'frame_number' for correct diff calculations\n",
    "df.sort_values(by=['id', 'frame_number'], inplace=True)\n",
    "\n",
    "# Calculate Movement Features (Δx and Δy)\n",
    "df['delta_x'] = df.groupby('id')['centroid_x'].diff().fillna(0)\n",
    "df['delta_y'] = df.groupby('id')['centroid_y'].diff().fillna(0)\n",
    "\n",
    "# Calculate Aggregated Features for each ID\n",
    "aggregations = {\n",
    "    'delta_x': ['mean','max', 'min','std'],\n",
    "    'delta_y': ['mean','max', 'min','std'],\n",
    "}\n",
    "aggregated_features = df.groupby('id').agg(aggregations).reset_index()\n",
    "\n",
    "# Correct the naming of the aggregated columns\n",
    "aggregated_features.columns = ['id'] + [f'{var}_{stat}' for var, stats in aggregations.items() for stat in stats]\n",
    "\n",
    "# Correctly merge aggregated features back to the original dataframe\n",
    "df = pd.merge(df, aggregated_features, on='id', how='left')\n",
    "\n",
    "# Calculate Sequence Features (net movement direction)\n",
    "df['net_movement_x'] = df.groupby('id')['delta_x'].transform('sum')\n",
    "df['net_movement_y'] = df.groupby('id')['delta_y'].transform('sum')\n",
    "\n",
    "df.to_csv(TMP_130, index=False)\n",
    "\n",
    "print(\"Updated CSV saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV to SQL LITE [110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "def convert_csv_to_sqlite(csv_file_path, db_file_path, table_name='bbox_data'):\n",
    "    # Load the CSV file into a pandas DataFrame\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    \n",
    "    # Create a connection to the SQLite database\n",
    "    conn = sqlite3.connect(db_file_path)\n",
    "    \n",
    "    # Write the data to a SQLite table\n",
    "    df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "    \n",
    "    # Close the connection\n",
    "    conn.close()\n",
    "\n",
    "BASE_FOLDER_NAME = 'results'\n",
    "CSV_FILE_PATH = 'conce_bbox.csv'\n",
    "\n",
    "CSV_FILE_PATH = os.path.join(BASE_FOLDER_NAME, CSV_FILE_PATH)\n",
    "\n",
    "db_file_path = f'{BASE_FOLDER_NAME}/bbox_data.db'\n",
    "convert_csv_to_sqlite(CSV_FILE_PATH, db_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQLite -> CSV [120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "def convert_sqlite_to_csv(db_file_path, csv_file_path, table_name='bbox_data'):\n",
    "    # Create a connection to the SQLite database\n",
    "    conn = sqlite3.connect(db_file_path)\n",
    "    \n",
    "    # Read the table into a pandas DataFrame\n",
    "    df = pd.read_sql_query(f\"SELECT * FROM {table_name}\", conn)\n",
    "    \n",
    "    # Write the DataFrame to a CSV file\n",
    "    df.to_csv(csv_file_path, index=False)\n",
    "    \n",
    "    # Close the connection\n",
    "    conn.close()\n",
    "\n",
    "BASE_FOLDER_NAME = 'results'\n",
    "\n",
    "db_file_path = f'{BASE_FOLDER_NAME}/bbox_data.db'\n",
    "CSV_FILE_PATH = 'from_sql_bbox.csv'\n",
    "CSV_FILE_PATH = os.path.join(BASE_FOLDER_NAME, CSV_FILE_PATH)\n",
    "\n",
    "convert_sqlite_to_csv(db_file_path, CSV_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updates labels from SQLite to a new bbox.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9095/3189779983.py:22: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'BAD' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  conce_bbox_df.at[index, 'label_direction'] = label_direction_map[ID]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV files into pandas dataframes\n",
    "conce_bbox_df = pd.read_csv('results/conce_bbox.csv')\n",
    "from_sql_bbox_df = pd.read_csv('results/from_sql_bbox.csv')\n",
    "\n",
    "# Create mappings for updates\n",
    "label_img_map = from_sql_bbox_df.set_index('img_name')['label_img'].to_dict()\n",
    "label_direction_map = from_sql_bbox_df.set_index('id')['label_direction'].to_dict()\n",
    "\n",
    "# Update conce_bbox DataFrame\n",
    "for index, row in conce_bbox_df.iterrows():\n",
    "    img_name = row['img_name']\n",
    "    ID = row['id']\n",
    "    \n",
    "    # Check and update label_img if img_name matches\n",
    "    if img_name in label_img_map:\n",
    "        conce_bbox_df.at[index, 'label_img'] = label_img_map[img_name]\n",
    "    \n",
    "    # Check and update label_direction if ID matches\n",
    "    if ID in label_direction_map:\n",
    "        conce_bbox_df.at[index, 'label_direction'] = label_direction_map[ID]\n",
    "\n",
    "# Optionally, save the updated dataframe back to a CSV\n",
    "conce_bbox_df.to_csv('results/conce_bbox.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
